{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Step 1: Camera calibration via chessboard images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object and Image points collected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "\n",
    "#images=os.listdir('camera_cal')\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        ''' Commenting this section to stop slowing code execution during dev work. \n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()'''\n",
    "print('Object and Image points collected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the object points and image points, undistort a calibration image and check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create camera calibration matrices using object and image points. \n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "## Verify capability of test matrix. \n",
    "calimg=mpimg.imread(images[0])\n",
    "cal_undst = cv2.undistort(calimg, mtx, dist, None, mtx)\n",
    "testimg=mpimg.imread('./test_images/test1.jpg')\n",
    "test_undst = cv2.undistort(testimg, mtx, dist, None, mtx)\n",
    "\n",
    "\n",
    "## Switch to inline plotting\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "f1, ax1 = plt.subplots(2, 2,figsize=(15,10));\n",
    "ax1[0,0].imshow(calimg)\n",
    "ax1[0,0].set_title('Original Cal Image',fontsize=20);\n",
    "ax1[0,1].imshow(cal_undst)\n",
    "ax1[0,1].set_title('Undistorted Cal Image',fontsize=20);\n",
    "ax1[1,0].imshow(testimg)\n",
    "ax1[1,0].set_title('Original Test Image',fontsize=20);\n",
    "ax1[1,1].imshow(test_undst)\n",
    "ax1[1,1].set_title('Undistorted Test Image',fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to work as expected.  On to thresholding. \n",
    "\n",
    "### Step 2. Colorspace and gradient thresholding to produce binary output.\n",
    "\n",
    "For this I intend to use all of the test images but first I will define each function individually and test on a single test image to verify function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous projects and lessons, the YUV and LAB colorspaces showed strenghts in identifying features. I am going to create helper functions for that as well. The HLS mentioned in this lesson is included as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def yuv_chn(img,channelIndex):\n",
    "    tgt_channel = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)[:, :, channelIndex]\n",
    "    return tgt_channel\n",
    "\n",
    "def lab_chn(img,channelIndex):\n",
    "    tgt_channel = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)[:, :, channelIndex]\n",
    "    return tgt_channel\n",
    "\n",
    "def hsv_chn(img,channelIndex):\n",
    "    tgt_channel = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)[:, :, channelIndex]\n",
    "    return tgt_channel\n",
    "\n",
    "def hls_chn(img,channelIndex):\n",
    "    tgt_channel = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)[:, :, channelIndex]\n",
    "    return tgt_channel\n",
    "\n",
    "def rgb_chn(img,channelIndex):\n",
    "    tgt_channel = img[:, :, channelIndex]\n",
    "    return tgt_channel\n",
    "\n",
    "def plot_test_group(imgfunc,labellist,testset):\n",
    "    f,ax=plt.subplots(len(testset),4,figsize=(17,20))\n",
    "    for j in range(len(testset)):\n",
    "        test_img=mpimg.imread(testset[j])\n",
    "        ax[j,0].imshow(imgfunc(test_img,0),cmap='gray')\n",
    "        ax[j,0].set_title(labellist[0])\n",
    "        ax[j,0].axis('off')\n",
    "        ax[j,1].imshow(imgfunc(test_img,1),cmap='gray')\n",
    "        ax[j,1].set_title(labellist[1])\n",
    "        ax[j,1].axis('off')\n",
    "        ax[j,2].imshow(imgfunc(test_img,2),cmap='gray')\n",
    "        ax[j,2].set_title(labellist[2])\n",
    "        ax[j,2].axis('off')\n",
    "        ax[j,3].imshow(test_img)\n",
    "        ax[j,3].set_title('Original')\n",
    "        ax[j,3].axis('off')\n",
    "    f.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "testset=glob.glob('./test_images/test*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yuvlabels=['Y Channel','U Channel','V Channel']\n",
    "plot_test_group(yuv_chn,yuvlabels,testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE THOUGHTS ON YUV RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lablabels=['L Channel','A Channel','B Channel']\n",
    "plot_test_group(lab_chn,lablabels,testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE THOUGHTS ON LAB RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgblabels=['R Channel','G Channel','B Channel']\n",
    "plot_test_group(rgb_chn,rgblabels,testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE THOUGHTS ON RGB RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsvlabels=['H Channel','S Channel','V Channel']\n",
    "plot_test_group(hsv_chn,hsvlabels,testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE THOUGHTS ON HSV RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hlslabels=['H Channel','L Channel','S Chanel']\n",
    "plot_test_group(hls_chn,hslabels,testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking a hint from the lesson I will create the s channel function from the HLS colorspace. \n",
    "\n",
    "def s_chn_bin(img,thresh=(0,255)):\n",
    "    s_channel = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)[:, :, 2]\n",
    "    bin_out=np.zeros_like(s_channel)\n",
    "    bin_out[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return bin_out\n",
    "\n",
    "## Test functions using previously loaded image\n",
    "plt.imshow(s_chn_bin(testimg,(20,50)),cmap='gray');\n",
    "\n",
    "\n",
    "\n",
    "### Create a function to apply thresholds to binary images. \n",
    "\n",
    "def applythresh(single_chan_img,thresh=(0,255)):\n",
    "    bin_out=np.zeros_like(single_chan_img)\n",
    "    bin_out[(single_chan_img >= thresh[0]) & (single_chan_img <= thresh[1])] = 1\n",
    "    return bin_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
